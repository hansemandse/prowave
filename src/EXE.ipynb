{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProWave - WaveNet-based Protein Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Hans Jakob Damsgaard & Lucas Balling\n",
    "\n",
    "02456 Deep Learning project: ProGen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the commmand below if you have not yet installed the [TAPE project](https://github.com/songlab-cal/tape)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tape_proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import tape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the data\n",
    "\n",
    "We were unable to make the data download script, `download_data.sh`, run from Jupyter, so instead we ran it manually and simply placed the resulting files in the right folder for TAPE to find them. We import all the data in the LMDB format as it is most easily worked with in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tape.datasets import LanguageModelingDataset\n",
    "\n",
    "# Data stored under `<data-path>/data`\n",
    "#data_path = '/Users/lucasballing/Desktop/DeepLearningProject/prowave-main/data/'\n",
    "data_path = 'E:/Pfam/data/'\n",
    "train_data   = LanguageModelingDataset(data_path, 'train')\n",
    "valid_data   = LanguageModelingDataset(data_path, 'valid')\n",
    "holdout_data = LanguageModelingDataset(data_path, 'holdout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding data features\n",
    "\n",
    "To get a good understanding of the data provided in the imported dataset, we provide plots of certain features and their ranges. Data is already split into the three required subsets; train, validation, and holdout by TAPE, so it is also interesting to understand this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sizes\n",
    "print(f'Training data has shape ({len(train_data)}, {len(train_data[0])})')\n",
    "print(f'Validation data has shape ({len(valid_data)}, {len(valid_data[0])})')\n",
    "print(f'Holdout data has shape ({len(holdout_data)}, {len(holdout_data[0])})')\n",
    "\n",
    "# Original data columns\n",
    "from tape.datasets import LMDBDataset\n",
    "lmdb_train = LMDBDataset(data_path+'pfam/pfam_train.lmdb')\n",
    "print(f'File data entries look like this: {lmdb_train[0]}')\n",
    "del lmdb_train\n",
    "\n",
    "# Data columns - all subsets are taken from the same overall dataset, so the columns are the same\n",
    "# From combining information from LMDBDataset and LanguageModelingDataset, we know the columns are\n",
    "# - IUPAC-encoded protein string\n",
    "# - Input mask (for masked-token prediction)\n",
    "# - Protein clan\n",
    "# - Protein family\n",
    "# The protein ID (i.e., its number within its clan and family) is not included\n",
    "print(f'Encoded data entries look like this: {train_data[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setify(data):\n",
    "    \"\"\"\n",
    "    Produces summary statistics for the provided datasets.\n",
    "\n",
    "    Args:\n",
    "     `data`: a list of datasets\n",
    "\n",
    "    Returns a tuple of three lists;\n",
    "     `uniques` representing sets of clans and families in each of the datasets\n",
    "     `perclan` representing tuples of clan ID and protein count\n",
    "     `perfam`  representing tuples of family ID and protein count\n",
    "    \"\"\"\n",
    "    uniques = [[set() for _ in range(len(data))] for _ in range(2)]\n",
    "    perclan = [{} for _ in range(len(data))]\n",
    "    perfam  = [{} for _ in range(len(data))]\n",
    "    for index, d in enumerate(data):\n",
    "        for i in range(len(d)):\n",
    "            # Fetch this entry\n",
    "            row  = d[i]\n",
    "            clan = row[2]\n",
    "            fam  = row[3]\n",
    "\n",
    "            # Add clan and family IDs to sets\n",
    "            uniques[0][index].add(clan) # add clan\n",
    "            uniques[1][index].add(fam) # add family\n",
    "\n",
    "            # Count proteins in this clan\n",
    "            if clan not in perclan[index]:\n",
    "                perclan[index][clan] = 1\n",
    "            else:\n",
    "                perclan[index][clan] += 1\n",
    "\n",
    "            # Count proteins in this family\n",
    "            if fam not in perfam[index]:\n",
    "                perfam[index][fam] = 1\n",
    "            else:\n",
    "                perfam[index][fam] += 1\n",
    "\n",
    "    return uniques, [x.items() for x in perclan], [x.items() for x in perfam]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch results from all splits\n",
    "results = setify([train_data, valid_data, holdout_data])\n",
    "\n",
    "# Clans in splits\n",
    "clans = results[0][0]\n",
    "print(f'Unique clans in training data {len(clans[0])}')\n",
    "print(f'Unique clans in validation data {len(clans[1])}')\n",
    "print(f'Unique clans in holdout data {len(clans[2])}')\n",
    "\n",
    "# Families in splits\n",
    "families = results[0][1]\n",
    "print(f'Unique families in training data {len(families[0])}')\n",
    "print(f'Unique families in validation data {len(families[1])}')\n",
    "print(f'Unique families in holdout data {len(families[2])}')\n",
    "\n",
    "# PRINTS:\n",
    "# Unique clans in training data 623\n",
    "# Unique clans in validation data 623\n",
    "# Unique clans in holdout data 8\n",
    "# Unique families in training data 17737\n",
    "# Unique families in validation data 15974\n",
    "# Unique families in holdout data 28\n"
   ]
  },
  {
   "source": [
    "We will now plot some histograms on number of proteins in each clan and family across all three splits."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of protein counts in clans\n",
    "# TRAINING\n",
    "df = pd.DataFrame(results[1][0], columns=['Clan', 'Count'])\n",
    "sns.displot(df, x='Clan')\n",
    "plt.title('Training - Protein count vs Clan')\n",
    "plt.show()\n",
    "\n",
    "# VALIDATION\n",
    "df = pd.DataFrame(results[1][1], columns=['Clan', 'Count'])\n",
    "sns.displot(df, x='Clan')\n",
    "plt.title('Validation - Protein count vs Clan')\n",
    "plt.show()\n",
    "\n",
    "# HOLDOUT\n",
    "df = pd.DataFrame(results[1][2], columns=['Clan', 'Count'])\n",
    "sns.displot(df, x='Clan')\n",
    "plt.title('Holdout - Protein count vs Clan')\n",
    "plt.show()\n",
    "\n",
    "# Histograms of protein counts in families\n",
    "# TRAINING\n",
    "df = pd.DataFrame(results[2][0], columns=['Family', 'Count'])\n",
    "sns.displot(df, x='Family')\n",
    "plt.title('Training - Protein count vs Clan')\n",
    "plt.show()\n",
    "\n",
    "# VALIDATION\n",
    "df = pd.DataFrame(results[2][1], columns=['Family', 'Count'])\n",
    "sns.displot(df, x='Family')\n",
    "plt.title('Validation - Protein count vs Clan')\n",
    "plt.show()\n",
    "\n",
    "# HOLDOUT\n",
    "df = pd.DataFrame(results[2][2], columns=['Family', 'Count'])\n",
    "sns.displot(df, x='Family')\n",
    "plt.title('Holdout - Protein count vs Clan')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}